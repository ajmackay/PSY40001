[["index.html", "PSY40001 SPSS to R notes Introduction", " PSY40001 SPSS to R notes Aaron Mackay 2021-09-02 Introduction The aim of this book is to go through each weeks PSY40001 lab and to recreate (or at least try to recreate) the exercises and output performed in SPSS in R. Depending on how intense the lab is (and how much spare time I have) I will aim to update this book before the following weeks lab. I have made this book public on github so feel free to download the code and add or edit anything. This book assumes a basic understanding as to how R and RStudio work, however I will endevour to make the steps as easy to follow as possible. If you have any questions then please feel free to reach out and email me at mackay_aaron@protonmail.com Enjoy! Aaron "],["data-screening-and-missing-values.html", "Week 1 Data Screening and Missing Values Part 1: Data Exploration Part 2: Missing Value Analysis", " Week 1 Data Screening and Missing Values The packages that we will use for this weeks exercises are as follows: library(tidyverse) # For general functions library(haven) # For importing SPSS file into R library(naniar) # Visualising missing data library(knitr) # For general tables Part 1: Data Exploration Importing SPSS file into R Importing SPSS files into R is easy with the haven package. lab1_raw &lt;- read_sav(&quot;data/lab1data.sav&quot;); knitr::kable( head(lab1_raw) ); nicname sex height border vegitarian prevmark hopemark crit 2 150 1 1 85 95 slim NA NA NA 2 NA NA kac 2 167 1 1 50 55 dusty 2 145 4 1 50 60 princess 2 NA 1 1 NA 85 Bean 1 189 3 1 80 80 Set Up Missing Values R automatically codes missing values with the NA symbol. While this can make things easier when running certain analyses, it does restrict us in the sense that we cannot easily define what a specific missing value represents (for example, we are unable to distinguish a missing value that is due to a participant refusing to answer the question with a missing value that was due to the researcher forgetting to ask). We can, however easily see how many missing values there are for each variable in our dataset: knitr::kable( summary(lab1_raw), caption = &quot;Summary of Raw Data&quot; ); Table 1.1: Summary of Raw Data nicname sex height border vegitarian prevmark hopemark Length:41 Min. :1.000 Min. :145.0 Min. : 1.000 Min. :1.00 Min. :45.00 Min. :40.00 Class :character 1st Qu.:1.000 1st Qu.:155.2 1st Qu.: 1.000 1st Qu.:1.00 1st Qu.:63.50 1st Qu.:75.00 Mode :character Median :2.000 Median :166.0 Median : 2.000 Median :1.00 Median :69.00 Median :80.00 NA Mean :1.615 Mean :166.3 Mean : 2.361 Mean :1.15 Mean :69.34 Mean :78.23 NA 3rd Qu.:2.000 3rd Qu.:178.0 3rd Qu.: 3.000 3rd Qu.:1.00 3rd Qu.:79.00 3rd Qu.:85.00 NA Max. :2.000 Max. :198.0 Max. :10.000 Max. :2.00 Max. :89.00 Max. :99.00 NA NAs :2 NAs :7 NAs :5 NAs :1 NAs :6 NAs :2 Modyfing the data Insert new Variable To create new variables inside a dataframe in R, we can use the mutate function. lab1_mod &lt;- lab1_raw %&gt;% mutate(dog = NA); And if we want to rearrange our variables so that dog is next to nicname we can do so by specifying the order of the index. lab1_mod &lt;- lab1_mod[,c(1,8,2:7)] knitr::kable( head(lab1_mod) ); nicname dog sex height border vegitarian prevmark hopemark crit NA 2 150 1 1 85 95 slim NA NA NA NA 2 NA NA kac NA 2 167 1 1 50 55 dusty NA 2 145 4 1 50 60 princess NA 2 NA 1 1 NA 85 Bean NA 1 189 3 1 80 80 Inputting Data Inputting data manually is not as intuitive in R as it is in SPSS as you cannot just click and edit specific entries. While this may seem cumbersome at first, it does ensure that you cannot accidentally delete or edit entries and any editting that is performed is documented (as long as you are saving the syntax). In this case, we just need a random assortment of True and False for our dog variable. This can be achieved with the sample function. set.seed(1) lab1_mod$dog &lt;- c(sample(c(&quot;True&quot;, &quot;False&quot;), 41, replace = TRUE)); knitr::kable( head(lab1_mod) ); nicname dog sex height border vegitarian prevmark hopemark crit True 2 150 1 1 85 95 slim False NA NA NA 2 NA NA kac True 2 167 1 1 50 55 dusty True 2 145 4 1 50 60 princess False 2 NA 1 1 NA 85 Bean True 1 189 3 1 80 80 And if we want to edit a specific entry, we can do so by specifying the corresponding index. lab1_mod$dog[3] &lt;- &quot;FALSE&quot; lab1_mod$dog[3]; ## [1] &quot;FALSE&quot; Or you can use the which function to return the index. lab1_mod$nicname[which(lab1_mod$nicname == &quot;dusty&quot;)] &lt;- &quot;doodles&quot; head(lab1_mod$nicname) ## [1] &quot;crit&quot; &quot;slim&quot; &quot;kac&quot; &quot;doodles&quot; &quot;princess&quot; &quot;Bean&quot; Compute new Variable The mutate function makes it easy to create new variables from existing variables. lab1_mod &lt;- lab1_mod %&gt;% mutate(diffmark = prevmark - hopemark); knitr::kable( head(lab1_mod) ); nicname dog sex height border vegitarian prevmark hopemark diffmark crit True 2 150 1 1 85 95 -10 slim False NA NA NA 2 NA NA NA kac FALSE 2 167 1 1 50 55 -5 doodles True 2 145 4 1 50 60 -10 princess False 2 NA 1 1 NA 85 NA Bean True 1 189 3 1 80 80 0 Edit Variable name* **This was not part of the week 1 lab, but the variable name vegitarian could use a little correcting!* colnames(lab1_mod)[colnames(lab1_mod) == &quot;vegitarian&quot;] &lt;- &quot;vegetarian&quot; colnames(lab1_mod) ## [1] &quot;nicname&quot; &quot;dog&quot; &quot;sex&quot; &quot;height&quot; &quot;border&quot; ## [6] &quot;vegetarian&quot; &quot;prevmark&quot; &quot;hopemark&quot; &quot;diffmark&quot; Part 2: Missing Value Analysis Univariate Statistics The table1 package allows us to quickly and easily see the number of missing values and their respective proportions. table1::table1(~height + prevmark + hopemark + border + sex + vegetarian, data = lab1_mod); Overall(N=41) height in centermeters Mean (SD) 166 (15.6) Median [Min, Max] 166 [145, 198] Missing 7 (17.1%) What is your average previous mark in stats? Mean (SD) 69.3 (11.9) Median [Min, Max] 69.0 [45.0, 89.0] Missing 6 (14.6%) What is your hoped for mark in this subject? Mean (SD) 78.2 (12.1) Median [Min, Max] 80.0 [40.0, 99.0] Missing 2 (4.9%) birth order Mean (SD) 2.36 (1.66) Median [Min, Max] 2.00 [1.00, 10.0] Missing 5 (12.2%) Gender Mean (SD) 1.62 (0.493) Median [Min, Max] 2.00 [1.00, 2.00] Missing 2 (4.9%) Are you a vegetarian Mean (SD) 1.15 (0.362) Median [Min, Max] 1.00 [1.00, 2.00] Missing 1 (2.4%) Separate Variance T-Tests Unfortunately I am yet to find a simple way to perform these tests in R. If you have any ideas as to how to get an output similar to the one shown in SPSS then please feel free to add them here! Missing and Tabulated Patterns The naniar package provides easy to use tools to visualise the pattern of missing data in a similar way to the Tabulated Patterns table in SPSS. lab1_mod %&gt;% select(height, prevmark, hopemark, border, sex, vegetarian) %&gt;% vis_miss(); gg_miss_upset(lab1_mod) Littles MCAR Test Unfortunately again I was not able to find much in regards to a simple way to perform Littles MCAR test on the missing data. The closest that I got was to this persons github who has created a function to perform the test. I have used it below and as you can see it returns similar (but not the same) results as the test in SPSS, however I cannot vouch for the mathematical reliability of the function. lab1_mcar &lt;- lab1_mod %&gt;% select(height, prevmark, hopemark, border); lab1_mcar &lt;- mcar(lab1_mcar); ## Iterations of EM: ## 1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...16...17...18...19...20...21... ## this could take a while data.frame(chi_square = lab1_mcar[[&quot;chi.square&quot;]], df = lab1_mcar[[&quot;df&quot;]], p_value = lab1_mcar[[&quot;p.value&quot;]]); ## chi_square df p_value ## 1 19.41084 14 0.1498372 "],["intro-to-regression.html", "Week 2 Intro to Regression Data Screening 2.1 Conducting a Multiple Regression", " Week 2 Intro to Regression The packages that I used for this weeks exercises are as follows: library(tidyverse) # For general functions library(haven) # For importing SPSS file into R Importing data: lab2_raw &lt;- read_sav(&quot;data/lab2data.sav&quot;); Data Screening Quick way to see if any variables have missing data apply(is.na(lab2_raw), 2, which); ## $id ## integer(0) ## ## $raceab ## integer(0) ## ## $socialid ## integer(0) ## ## $selfest ## integer(0) ## ## $CBT ## integer(0) ## ## $anxiety ## [1] 59 And we can see that the observation 59 has missing data for Anxiety. For the sake of our analysis we will just remove this observation (Which is what I believe we did in the Lab); lab2 &lt;- lab2_raw %&gt;% na.omit() sum(is.na(lab2$anxiety)) # Just testing that we did remove the NA ## [1] 0 2.1 Conducting a Multiple Regression I havent yet found a way to have all the regression output as nicely formatted as it appears in SPSS. The closest I could get was to save the regression output in a separate APA formatted document, which I achieved with using the function apa.reg.table located in the apaTables package. The APA output is saved in a folder called output which you can access from gitHub if you so desire. 2.1.1 Descriptives table1::table1(~anxiety + raceab + socialid + selfest + CBT, data = lab2) Overall(N=81) anxiety Mean (SD) 26.1 (2.25) Median [Min, Max] 27.0 [22.0, 30.0] racial abuse score Mean (SD) 5.59 (1.95) Median [Min, Max] 5.00 [3.00, 10.0] social identity score Mean (SD) 5.86 (2.61) Median [Min, Max] 6.00 [-1.00, 12.0] self-esteem score Mean (SD) 4.72 (2.00) Median [Min, Max] 4.00 [1.00, 9.00] CBT program efficacy Mean (SD) 22.6 (3.80) Median [Min, Max] 22.0 [15.0, 31.0] 2.1.2 Multiple Regression The following table provides all the numbers needed to fill in the worksheet. lab2.lm &lt;- lm(anxiety ~ socialid + selfest + raceab + CBT, data = lab2_raw); #Saving Linear Model in lab2.lm object summary(lab2.lm) ## ## Call: ## lm(formula = anxiety ~ socialid + selfest + raceab + CBT, data = lab2_raw) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.9060 -0.8924 0.0391 0.8220 4.1153 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 18.44501 0.91761 20.101 &lt; 2e-16 *** ## socialid 0.17613 0.07376 2.388 0.0194 * ## selfest 0.61165 0.11618 5.265 1.26e-06 *** ## raceab 0.05204 0.09258 0.562 0.5757 ## CBT 0.15186 0.03885 3.909 0.0002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.261 on 76 degrees of freedom ## (1 observation deleted due to missingness) ## Multiple R-squared: 0.7012, Adjusted R-squared: 0.6855 ## F-statistic: 44.6 on 4 and 76 DF, p-value: &lt; 2.2e-16 Output rundown Residuals If the residuals are roughly centered around zero and have a similar spread on each side then the model probably fits the assumption of homoscedasticity. Coefficients Estimate: The estimated effect (aka regression coefficient). Tells us how much the DV increases/decreases per one point increase in the predictor (controlling for other predictors). Std. Error: The standard error of the estimate (regression coefficient). Indicates how much variation there is around the estimate. t-value: Displays the test statistic. By default, the test statistic will be the t-value from a two-sided t-test. The larger the test statistic, the less likely that the results were from chance alone. Pr(&gt;|t|): P-value "],["advanced-multiple-regression.html", "Week 3 Advanced Multiple Regression 3.1 Moderation (Simple Multiplicative Interaction)", " Week 3 Advanced Multiple Regression Mediation and Moderation Packages Used: library(tidyverse) Importing Data: lab3.raw &lt;- haven::read_sav(&quot;data/lab3data.sav&quot;) view(lab3.raw) 3.1 Moderation (Simple Multiplicative Interaction) We will be looking at whether there is an interaction effect between Perceived Support and Conscientiousness on Honours Grade. Basic Steps Centre the predictors Compute the interaction term Fit the regression model with and without the interaction using heirarchical regression Interpret the interaction with the aid of plots Centre Variables lab3 &lt;- lab3.raw %&gt;% mutate(conscie.cent = conscie - mean(conscie), psupport.cent = psupport - mean(psupport)) Compute Interaction Multiply the two centred variables together. Note: You dont actually need to do this in R, you can just input the interaction term straight into the model and it will do the calculation. lab3 &lt;- lab3 %&gt;% mutate(conscie.psupport = conscie.cent * psupport.cent) Heirarchical Regression m0 &lt;- lm(honsgrad ~ 1, data = lab3) # To obtain total Sums of Squares m1 &lt;- lm(honsgrad ~ conscie.cent + psupport.cent, data = lab3) m2 &lt;- lm(honsgrad ~ conscie.cent*psupport.cent, data = lab3) # You can also do this: lm(honsgrad ~ conscie.cent + psupport.cent + conscie.cent:psupport.cent, data = lab3) Interpret Output Significance of change We can calculate whether the model with interaction explains a significant amount more variance than the model without interaction by using anova(). anova(m1, m2) ## Analysis of Variance Table ## ## Model 1: honsgrad ~ conscie.cent + psupport.cent ## Model 2: honsgrad ~ conscie.cent * psupport.cent ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 47 1661.3 ## 2 46 1162.2 1 499.07 19.753 5.516e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The above table indicates that there is a significant improvement in the model including interaction: F(1, 46) = 19.753, p &lt; .001. We can calculate the change in variance explained by looking at the R2 values of each model. summary(m1) ## ## Call: ## lm(formula = honsgrad ~ conscie.cent + psupport.cent, data = lab3) ## ## Residuals: ## Min 1Q Median 3Q Max ## -15.249 -4.885 0.861 4.553 11.636 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 78.0600 0.8408 92.842 &lt; 2e-16 *** ## conscie.cent 1.6862 0.3618 4.660 2.63e-05 *** ## psupport.cent 1.3839 0.3353 4.127 0.000149 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.945 on 47 degrees of freedom ## Multiple R-squared: 0.489, Adjusted R-squared: 0.4672 ## F-statistic: 22.49 on 2 and 47 DF, p-value: 1.408e-07 summary(m2) ## ## Call: ## lm(formula = honsgrad ~ conscie.cent * psupport.cent, data = lab3) ## ## Residuals: ## Min 1Q Median 3Q Max ## -11.100 -3.861 -0.154 3.173 12.375 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 77.5779 0.7191 107.885 &lt; 2e-16 *** ## conscie.cent 1.0031 0.3424 2.930 0.00526 ** ## psupport.cent 1.3436 0.2836 4.737 2.11e-05 *** ## conscie.cent:psupport.cent 0.5834 0.1313 4.444 5.52e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.026 on 46 degrees of freedom ## Multiple R-squared: 0.6425, Adjusted R-squared: 0.6192 ## F-statistic: 27.56 on 3 and 46 DF, p-value: 2.37e-10 The model with interaction has an \\(R^2\\) of .642 and the model without has an \\(R^2\\) of .489. The difference (\\(.642-.489=.153\\)) suggests that the model with interaction accounts for 15% more variance over and above the main effects of the model without interaction. Plotting Interaction https://stats.idre.ucla.edu/r/seminars/interactions-r/ TBC "],["wk-4.html", "Week 4 Wk 4", " Week 4 Wk 4 "],["wk-5.html", "Week 5 Wk 5", " Week 5 Wk 5 "],["wk-6.html", "Week 6 Wk 6", " Week 6 Wk 6 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
